AGENT 3 TASK — APPLY STEPS 4–7 (ONE PROMPT)

Goal: Wire in the inclusive TutorMind prompt + guardrails + answer checking with minimal edits; add env vars; add tests. Assume `server/services/guardrails.ts`, `server/services/answerCheck.ts`, and `server/prompts/tutorMind.ts` already exist.

────────────────────────────────────────────────────────────────────────

EDIT: server/services/openai.ts

1) Add imports at the top:
import { guardrails } from '../services/guardrails';
import { answerChecker } from '../services/answerCheck';
import { getTutorMindPrompt } from '../prompts/tutorMind';

2) Where the system prompt is constructed, replace/augment with:
const systemPrompt = getTutorMindPrompt(context?.lessonPlan);

3) After the model generates `response` but BEFORE returning to the client, insert this block (keep everything else intact, no extra LLM calls):

// --- TutorMind post-processing (inclusive + corrections + format) ---
let finalResponse = guardrails.sanitizeTutorQuestion(response);        // inclusive rephrase
finalResponse = guardrails.avoidRepeat(sessionId, finalResponse);      // anti-repeat
if (context?.lastQuestion && context?.expectedAnswer && userMessage) { // corrections
  const res = answerChecker.checkAnswer(
    context.expectedAnswer,
    userMessage,
    context.questionType || 'auto'
  );
  if (!res.ok) finalResponse = `${res.msg} ${finalResponse}`;
}
finalResponse = guardrails.enforceFormat(finalResponse);               // ≤2 sentences, ends with '?'
return finalResponse;

4) If this file maintains a `messages` array for the LLM call, ensure we never fabricate user turns (insert just before the LLM request or wherever messages are finalized):
messages = guardrails.preventUserFabrication(messages);

Do not modify unrelated logic. Keep edits minimal.

────────────────────────────────────────────────────────────────────────

ENV VARS — add to .env (dev and deploy):

TUTOR_INCLUSIVE_MODE=true
TUTOR_MAX_SENTENCES=2
TUTOR_REQUIRE_QUESTION=true
TUTOR_DEBUG_CORRECTIONS=true

────────────────────────────────────────────────────────────────────────

TESTS — create tests/empathy.test.ts (Jest):

import { describe, test, expect } from '@jest/globals';
import { guardrails } from '../server/services/guardrails';
import { answerChecker } from '../server/services/answerCheck';
import { getTutorMindPrompt } from '../server/prompts/tutorMind';

describe('Tutor empathy & corrections', () => {
  test('Ableist prompt is rephrased', () => {
    const bad = 'Count how many fingers do you have on your hand?';
    const s = guardrails.sanitizeTutorQuestion(bad).toLowerCase();
    expect(s).not.toContain('your hand');
    expect(s).not.toContain('you have');
    expect(s.includes('typically') || s.includes('a hand') || s.includes('imagine')).toBe(true);
  });

  test('Wrong math answer triggers gentle correction', () => {
    const r = answerChecker.checkAnswer('4', '5', 'math');
    expect(r.ok).toBe(false);
    expect(r.msg).toMatch(/4/);
    expect(r.msg.toLowerCase()).toMatch(/not quite|actually|correct/);
  });

  test('Repeat guard changes wording', () => {
    const session = 's1';
    const a = guardrails.avoidRepeat(session, 'What is 2 plus 2?');
    const b = guardrails.avoidRepeat(session, 'What is 2 plus 2?');
    expect(a).toBe('What is 2 plus 2?');
    expect(b).not.toBe('What is 2 plus 2?');
  });

  test('MCQ accepts multiple formats', () => {
    const ok = ['b','B','option b','answer b','2'].map(v =>
      answerChecker.checkAnswer('b', v, 'mcq').ok
    );
    expect(ok.every(Boolean)).toBe(true);
  });

  test('Number words count as correct', () => {
    expect(answerChecker.checkAnswer('4','four','math').ok).toBe(true);
    expect(answerChecker.checkAnswer('13','thirteen','math').ok).toBe(true);
  });

  test('Format enforcer ends with question and ≤2 sentences', () => {
    const out = guardrails.enforceFormat('Great work. The answer is 4.');
    expect(out.trim().endsWith('?')).toBe(true);
    const n = (out.match(/[.!?]+/g) || []).length;
    expect(n).toBeLessThanOrEqual(2);
  });

  test('System prompt contains inclusive + topic guard cues', () => {
    const p = getTutorMindPrompt({ subject: 'math', topic: 'addition', level: 'beginner' }).toLowerCase();
    expect(p).toContain('inclusive');
    expect(p).toContain('off-topic');
    expect(p).toContain('end with a question');
  });
});

────────────────────────────────────────────────────────────────────────

ACCEPTANCE CRITERIA
- Assistant never fabricates user turns.
- Ableist/assumptive phrasing is rewritten inclusively.
- Wrong answers produce a gentle correction + follow-up.
- Output is ≤2 sentences and always ends with a question.
- Duplicate assistant lines are avoided.
- Tests pass without modifying unrelated code.
